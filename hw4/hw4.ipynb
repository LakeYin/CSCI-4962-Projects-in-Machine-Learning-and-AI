{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.6rc1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6rc1 64-bit"
    },
    "interpreter": {
      "hash": "965a33b357934e9f83fc7ef133db771ae96b140076b3a892fdf40d2537a7764b"
    },
    "colab": {
      "name": "hw4.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhxD0Zt-x-iy"
      },
      "source": [
        "# Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP9G8bxdx-jL"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "train_set = tfds.load('imdb_reviews', split='train', as_supervised=True).take(5000)\n",
        "test_set = tfds.load('imdb_reviews', split='test', as_supervised=True).take(1000)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E3_8hI5x-jZ"
      },
      "source": [
        "# Prepare tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1uhgqSIx-jd"
      },
      "source": [
        "max_text_length = 0\n",
        "\n",
        "# training\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i, j in train_set:\n",
        "    i = str(i.numpy())\n",
        "    max_text_length = max(max_text_length, len(i))\n",
        "    X_train.append(i)\n",
        "    y_train.append(int(j))\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_text_length, padding='post')\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# testing\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i, j in test_set:\n",
        "    i = str(i.numpy())\n",
        "    X_test.append(i)\n",
        "    y_test.append(int(j))\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_text_length, padding='post')\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbl8Mr0Rx-jh"
      },
      "source": [
        "# Build the RNN\n",
        "We need to use an RNN to help predict positive/negative reviews because the order of words obviously matters in sentences. An embedding layer is needed to convert sequences of tokens into sequences of vectors that can be easily understood by the RNN layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z68kY8uyx-jk"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(10001, 128, mask_zero=True))\n",
        "model.add(keras.layers.SimpleRNN(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL8aNwG0x-jp"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvAo3Yk3x-jt",
        "outputId": "b562cb21-245c-4aea-ecf5-ed8d326c2f72"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "model.fit(X_train, y_train, epochs=epochs, validation_split=0.1, batch_size=256)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 762s 42s/step - loss: 0.6913 - binary_accuracy: 0.5158 - val_loss: 0.6899 - val_binary_accuracy: 0.5360\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 778s 43s/step - loss: 0.6530 - binary_accuracy: 0.7062 - val_loss: 0.6512 - val_binary_accuracy: 0.6040\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 773s 43s/step - loss: 0.5995 - binary_accuracy: 0.7698 - val_loss: 0.6313 - val_binary_accuracy: 0.6580\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 784s 44s/step - loss: 4282.6270 - binary_accuracy: 0.6813 - val_loss: 0.7717 - val_binary_accuracy: 0.4900\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 757s 42s/step - loss: 0.7514 - binary_accuracy: 0.5140 - val_loss: 0.9542 - val_binary_accuracy: 0.4860\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 746s 41s/step - loss: 0.7697 - binary_accuracy: 0.5180 - val_loss: 0.8752 - val_binary_accuracy: 0.4940\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 753s 42s/step - loss: 0.6720 - binary_accuracy: 0.5422 - val_loss: 0.7920 - val_binary_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 752s 42s/step - loss: 0.6087 - binary_accuracy: 0.5740 - val_loss: 0.7486 - val_binary_accuracy: 0.5140\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 758s 42s/step - loss: 0.5726 - binary_accuracy: 0.6053 - val_loss: 0.7232 - val_binary_accuracy: 0.5300\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 748s 42s/step - loss: 0.5476 - binary_accuracy: 0.6302 - val_loss: 0.7067 - val_binary_accuracy: 0.5360\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f60314850>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66PAK1msASIf"
      },
      "source": [
        "# Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImLBXPqFAidz",
        "outputId": "5b441ba4-c9f9-4409-98b0-eabfb340b9bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.metrics_names)\n",
        "print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'binary_accuracy']\n",
            "32/32 [==============================] - 49s 2s/step - loss: 0.6940 - binary_accuracy: 0.5480\n",
            "[0.6939795613288879, 0.5479999780654907]\n"
          ]
        }
      ]
    }
  ]
}