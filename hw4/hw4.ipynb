{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.8.6rc1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.6rc1 64-bit"
    },
    "interpreter": {
      "hash": "965a33b357934e9f83fc7ef133db771ae96b140076b3a892fdf40d2537a7764b"
    },
    "colab": {
      "name": "hw4.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhxD0Zt-x-iy"
      },
      "source": [
        "# Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP9G8bxdx-jL"
      },
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "train_set = tfds.load('imdb_reviews', split='train', as_supervised=True).take(5000)\n",
        "test_set = tfds.load('imdb_reviews', split='test', as_supervised=True).take(1000)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E3_8hI5x-jZ"
      },
      "source": [
        "# Prepare tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1uhgqSIx-jd"
      },
      "source": [
        "max_text_length = 0\n",
        "\n",
        "# training\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i, j in train_set:\n",
        "    i = str(i.numpy())\n",
        "    max_text_length = max(max_text_length, len(i))\n",
        "    X_train.append(i)\n",
        "    y_train.append(int(j))\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_text_length, padding='post')\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# testing\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i, j in test_set:\n",
        "    i = str(i.numpy())\n",
        "    X_test.append(i)\n",
        "    y_test.append(int(j))\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_text_length, padding='post')\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbl8Mr0Rx-jh"
      },
      "source": [
        "# Build the RNN\n",
        "We need to use an RNN to help predict positive/negative reviews because the order of words obviously matters in sentences. An embedding layer is needed to convert sequences of tokens into sequences of vectors that can be easily understood by the RNN layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z68kY8uyx-jk"
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(10001, 64, mask_zero=True))\n",
        "model.add(keras.layers.SimpleRNN(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL8aNwG0x-jp"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvAo3Yk3x-jt",
        "outputId": "a7454bc9-602a-4595-bee2-7e58cd25fa78"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "model.fit(X_train, y_train, epochs=epochs, validation_split=0.1, batch_size=256)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "18/18 [==============================] - 816s 45s/step - loss: 0.6926 - binary_accuracy: 0.5149 - val_loss: 0.6922 - val_binary_accuracy: 0.5140\n",
            "Epoch 2/5\n",
            "18/18 [==============================] - 805s 45s/step - loss: 0.6766 - binary_accuracy: 0.6829 - val_loss: 0.6765 - val_binary_accuracy: 0.5800\n",
            "Epoch 3/5\n",
            "18/18 [==============================] - 817s 45s/step - loss: 0.6168 - binary_accuracy: 0.7264 - val_loss: 0.6443 - val_binary_accuracy: 0.6280\n",
            "Epoch 4/5\n",
            "18/18 [==============================] - 821s 46s/step - loss: 0.5635 - binary_accuracy: 0.7320 - val_loss: 0.6643 - val_binary_accuracy: 0.5760\n",
            "Epoch 5/5\n",
            "18/18 [==============================] - 822s 46s/step - loss: 0.4797 - binary_accuracy: 0.8267 - val_loss: 0.6340 - val_binary_accuracy: 0.6620\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f31523d06d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66PAK1msASIf"
      },
      "source": [
        "# Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImLBXPqFAidz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9b3e8f-1e7c-49d8-cd72-fbfc7ff202f8"
      },
      "source": [
        "print(model.metrics_names)\n",
        "print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'binary_accuracy']\n",
            "32/32 [==============================] - 53s 2s/step - loss: 0.6246 - binary_accuracy: 0.6770\n",
            "[0.6245537996292114, 0.6769999861717224]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ouf3UmOyusq"
      },
      "source": [
        "# Create new model with LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5xc-zpRy2XT"
      },
      "source": [
        "model2 = keras.Sequential()\n",
        "model2.add(keras.layers.Embedding(10001, 64, mask_zero=True))\n",
        "model2.add(keras.layers.LSTM(128, activation='relu'))\n",
        "model2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB9WLW8tzGWQ"
      },
      "source": [
        "# Train the new model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moIqHpAqzJrn",
        "outputId": "42c20571-703a-4b33-93e5-84533cae8445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "model2.fit(X_train, y_train, epochs=epochs, validation_split=0.1, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6XKabSqzbfh"
      },
      "source": [
        "# Evaluate LSTM on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF-tj1usze8v"
      },
      "source": [
        "print(model2.metrics_names)\n",
        "print(model2.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}