{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "from tensorflow import keras\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_datasets as tfds\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "train_set = tfds.load('imdb_reviews', split='train', as_supervised=True)\r\n",
    "test_set = tfds.load('imdb_reviews', split='test', as_supervised=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare tokens"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "max_text_length = 0\r\n",
    "\r\n",
    "X_train = []\r\n",
    "y_train = []\r\n",
    "for i, j in train_set:\r\n",
    "    i = str(i.numpy())\r\n",
    "    max_text_length = max(max_text_length, len(i))\r\n",
    "    X_train.append(i)\r\n",
    "    y_train.append(int(j))\r\n",
    "\r\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\r\n",
    "tokenizer.fit_on_texts(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build the RNN\r\n",
    "We need to use an RNN to help predict positive/negative reviews because the order of words obviously matters in sentences. An embedding layer is needed to convert sequences of tokens into sequences of vectors that can be easily understood by the RNN layer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "model = keras.Sequential()\r\n",
    "model.add(keras.layers.Embedding(10001, 128, mask_zero=True))\r\n",
    "model.add(keras.layers.SimpleRNN(100, activation='relu'))\r\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\r\n",
    "\r\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.BinaryAccuracy()])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "epochs = 10\r\n",
    "\r\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\r\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_text_length, padding='post')\r\n",
    "\r\n",
    "X_train = np.array(X_train)\r\n",
    "y_train = np.array(y_train)\r\n",
    "\r\n",
    "model.fit(X_train, y_train, epochs=epochs, validation_split=0.1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "  4/704 [..............................] - ETA: 6:03:17 - loss: 0.6867 - binary_accuracy: 0.6452"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.6rc1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6rc1 64-bit"
  },
  "interpreter": {
   "hash": "965a33b357934e9f83fc7ef133db771ae96b140076b3a892fdf40d2537a7764b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}